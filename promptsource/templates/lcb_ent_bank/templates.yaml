dataset: lcb_ent_bank
templates:
  af1fa9cd-a73a-40f2-8fc9-0d2e5e97dcad: !Template
    answer_choices: incorrect ||| correct
    id: af1fa9cd-a73a-40f2-8fc9-0d2e5e97dcad
    jinja: "
{% for p,t in zip(premises, truths) %}\
\"{{ p }}\" is {{ t }}.\n\
{% endfor %}\
\n\
Answering \"{{ question }}\" with \"({{ answerKey }}) {{ answer }}\" is ||| ({{ answer_choices[label] }})"
    metadata: !TemplateMetadata
      choices_in_prompt: false
      languages:
        - en
      metrics:
        - Accuracy
      original_task: true
    name: truth
    reference: ''

  39f34a10-fe49-4ca8-a998-9457d5781f05: !Template
    answer_choices: False ||| True
    id: 39f34a10-fe49-4ca8-a998-9457d5781f05
    jinja: "
Given the following question \"{{ question }}\" and considering that:\n\
{% for p,t in zip(premises, truths) %}\
The sentence \"{{ p }}\" is {{ t }}.\n\
{% endfor %}\
\n\
Would the sentence \"{{ hypothesis }}\" be True or False?  ||| ({{ answer_choices[label] }})"
    metadata: !TemplateMetadata
      choices_in_prompt: false
      languages:
        - en
      metrics:
        - Accuracy
      original_task: true
    name: truth-question
    reference: ''